(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{220:function(v,_,a){"use strict";a.r(_);var t=a(0),r=Object(t.a)({},(function(){var v=this,_=v.$createElement,a=v._self._c||_;return a("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[a("h1",{attrs:{id:"제-1장-한눈에-보는-머신러닝"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#제-1장-한눈에-보는-머신러닝"}},[v._v("#")]),v._v(" 제 1장 한눈에 보는 머신러닝")]),v._v(" "),a("p",[v._v("광학문자 판독기와 스팸 필터가 대표적인 사례.")]),v._v(" "),a("h2",{attrs:{id:"머신러닝이란"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝이란"}},[v._v("#")]),v._v(" 머신러닝이란")]),v._v(" "),a("blockquote",[a("p",[v._v("명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구분야 - 아서 사무엘, 1959")])]),v._v(" "),a("p",[v._v("조금 더 공학적으로 정의하자면,")]),v._v(" "),a("blockquote",[a("p",[v._v("어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때, 경험 E로 인해 성능이 향상되었다면, 작업 T는 성능 P에 대해 경험 E로 학습한 것이다. - 톰 미첼, 1997")])]),v._v(" "),a("p",[v._v("스팸 필터라는 작업에서 훈련세트, 혹은 훈련사례, 샘플 등 훈련데이터는 경험 E가 되고, 이를 통해 필터 성능 "),a("strong",[v._v("정확도")]),v._v("가 향상되었다면, 이를 머신러닝이라고 부를 수 있다.")]),v._v(" "),a("h2",{attrs:{id:"머신러닝을-사용하는-이유"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝을-사용하는-이유"}},[v._v("#")]),v._v(" 머신러닝을 사용하는 이유")]),v._v(" "),a("p",[v._v("스팸 필터같은 경우, 계속 스팸 규칙을 업데이트 해주기 어려우므로, 데이터를 통해서 모델이 학습하여 자동으로 분류하도록 한다.")]),v._v(" "),a("p",[v._v("또 다른 분야로는 기존 방식으로 풀기 어려운 문제, 음성 인식 같은 문제를 예로 들 수 있다. 많은 데이터를 통해서 프로그램이 스스로 규칙을 만들어 낼 수 있다.")]),v._v(" "),a("p",[v._v("대용량의 데이터 속에서 겉으로는 보이지 않던 패턴을 찾아내는 것을 "),a("strong",[v._v("데이터 마이닝")]),v._v("이라고 한다.")]),v._v(" "),a("h2",{attrs:{id:"머신러닝-시스템의-종류"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝-시스템의-종류"}},[v._v("#")]),v._v(" 머신러닝 시스템의 종류")]),v._v(" "),a("ul",[a("li",[v._v("훈련을 위해 사람의 감독이 필요한지 아닌지: 지도, 비지도, 준지도, 강화학습")]),v._v(" "),a("li",[v._v("실시간으로 점진적으로 학습하는지 여부: 온라인 학습과 배치 학습")]),v._v(" "),a("li",[v._v("알고 있는 데이터 포인트에서 유사한 결과를 찾는 것인지, 아니면 패턴을 발견해서 예측하는 것인지: 사례기반 학습과 모델기반 학습")])]),v._v(" "),a("h3",{attrs:{id:"지도학습"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#지도학습"}},[v._v("#")]),v._v(" 지도학습")]),v._v(" "),a("p",[v._v("지도학습의 주요한 예는 분류(classification).")]),v._v(" "),a("p",[v._v("훈련 데이터에서 "),a("strong",[v._v("레이블")]),v._v("은 답을 의미하며, 각종 데이터를 **특성(feature)**라고 한다. "),a("strong",[v._v("속성")]),v._v("은 데이터 타입(예를 들어 컬럼명)을 의미하는데, 일반적으로 특성과 속성을 구분하지 않고 쓰는 편이다.")]),v._v(" "),a("p",[v._v("주요한 알고리즘으로는 다음과 같다.")]),v._v(" "),a("ul",[a("li",[v._v("k-Nearest Neighbors")]),v._v(" "),a("li",[v._v("선형 회귀")]),v._v(" "),a("li",[v._v("로지스틱 회귀")]),v._v(" "),a("li",[v._v("서포트 벡터 머신")]),v._v(" "),a("li",[v._v("결정 트리와 랜덤 포레스트")]),v._v(" "),a("li",[v._v("신경망")])]),v._v(" "),a("h3",{attrs:{id:"비지도-학습"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#비지도-학습"}},[v._v("#")]),v._v(" 비지도 학습")]),v._v(" "),a("p",[v._v("비지도 학습의 주요한 알고리즘은 다음과 같다.")]),v._v(" "),a("ul",[a("li",[v._v("군집\n"),a("ul",[a("li",[v._v("k-Means")]),v._v(" "),a("li",[v._v("계층 군집 분석")]),v._v(" "),a("li",[v._v("기댓값 최대화")])])]),v._v(" "),a("li",[v._v("시각화와 차원축소: 이상치 탐지\n"),a("ul",[a("li",[v._v("PCA")]),v._v(" "),a("li",[v._v("커널 PCA")]),v._v(" "),a("li",[v._v("지역적 선형 임베딩(LLE)")]),v._v(" "),a("li",[v._v("t-SNE (t-distributed Stochastic Neighbor Embedding): 언어들 간의 분포를 통해 개념 간의 거리를 시각화함")])])]),v._v(" "),a("li",[v._v("연관 규칙 학습: 슈퍼마켓에서 구매 목록 간의 유사성을 찾을 수 있다.\n"),a("ul",[a("li",[v._v("어프라이어리 (Apriori)")]),v._v(" "),a("li",[v._v("이클렛 (Eclat)")])])])]),v._v(" "),a("h3",{attrs:{id:"준지도-학습"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#준지도-학습"}},[v._v("#")]),v._v(" 준지도 학습")]),v._v(" "),a("p",[v._v("구글 포토 같은 경우가 대표적 예, 비지도 학습으로 사진을 분류하고, 분류된 사진에 사용자가 라벨링을 하면, 라벨링된 이름으로 사진을 분류해준다.")]),v._v(" "),a("p",[v._v("심층 신뢰 신경망(Deep Belief Network, DBN)과 제한된 볼츠만 머신(Restricted Boltzmann Machine, BRM)이 준지도 학습에 해당한다.")]),v._v(" "),a("h3",{attrs:{id:"강화학습"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#강화학습"}},[v._v("#")]),v._v(" 강화학습")]),v._v(" "),a("p",[v._v("학습하는 시스템을 "),a("strong",[v._v("에이전트")]),v._v("라고 부르고, "),a("strong",[v._v("보상(reward)")]),v._v(" 혹은 **벌점(penalty)**에 따라 최적의 **정책(policy)**을 찾는 모형이다. 게임을 수행하는 모형이 대표적인 예이며, 알파고가 일부 강화학습을 이용하였다.")]),v._v(" "),a("h2",{attrs:{id:"배치-학습과-온라인-학습"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#배치-학습과-온라인-학습"}},[v._v("#")]),v._v(" 배치 학습과 온라인 학습")]),v._v(" "),a("p",[v._v("배치 학습은 오프라인 학습이라고도 한다. 데이터셋을 통째로 넣고, 학습시킨다. 데이터가 갱신되면, 처음부터 다시 돌려야 한다.")]),v._v(" "),a("p",[v._v("온라인 학습은 점진적 학습이라고도 하며, 미니배치라고 부르는 작은 묶음단위로 학습을 한다. 이 경우 학습률이 중요하다. 학습률이 높으면, 예전 데이터를 쉽게 잃어버리게 되고, 반대로 학습률이 낮으면 시스템의 관성이 커져 쉽게 학습하지 못한다. 온라인 학습 시 주의할 점은 나쁜 데이터가 주입될 때 시스템 성능이 급격이 나빠진다. 따라서 주기적으로 백업과 모니터링을 해야하며, 성능이 나빠질 경우 복원 프로세스가 있어야 한다.")]),v._v(" "),a("h2",{attrs:{id:"사례기반-학습과-모델기반-학습"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#사례기반-학습과-모델기반-학습"}},[v._v("#")]),v._v(" 사례기반 학습과 모델기반 학습")]),v._v(" "),a("p",[v._v("사례기반 학습은 가장 가까운 기존 사례를 찾는다. 이 때, 가장 가까운 몇개 값의 평균으로 찾을 수도 있다.")]),v._v(" "),a("p",[v._v("모델기반 학습은 모델을 만들고, 이 모델이 얼마나 좋은지 측정하는 "),a("strong",[v._v("효용함수(utility function)")]),v._v(", 또는 **적합도 함수(fitness function)**를 정의하거나, 얼마나 나쁜지 측정하는 **비용 함수(cost function)**를 정의하여 훈련시킨다.")]),v._v(" "),a("h2",{attrs:{id:"머신러닝의-주요한-도전"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝의-주요한-도전"}},[v._v("#")]),v._v(" 머신러닝의 주요한 도전")]),v._v(" "),a("h3",{attrs:{id:"충분하지-않은-양의-훈련"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#충분하지-않은-양의-훈련"}},[v._v("#")]),v._v(" 충분하지 않은 양의 훈련")]),v._v(" "),a("p",[v._v("마소의 연구자인 미셸 반코와 에릭 브릴이 발표한 2001년 논문("),a("a",{attrs:{href:"https://www.semanticscholar.org/paper/Scaling-to-Very-Very-Large-Corpora-for-Natural-Banko-Brill/639b4cac06148e9f91736ba36ad4a1b97fcdfd6a",target:"_blank",rel:"noopener noreferrer"}},[v._v("Scaling to Very Very Large Corpora for Natural Language Disambiguation"),a("OutboundLink")],1),v._v(")에서 데이터가 충분히 주어지면 모델과 상관없이 문제를 거의 비슷하게 잘 처리한다는 점을 보였다.")]),v._v(" "),a("h3",{attrs:{id:"대표성이-없는-훈련-데이터"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#대표성이-없는-훈련-데이터"}},[v._v("#")]),v._v(" 대표성이 없는 훈련 데이터")]),v._v(" "),a("p",[v._v("샘플이 작으면 샘플링 잡음이 생기고, 샘플이 크더라도 샘플링 편향이 생길 수 있다.")]),v._v(" "),a("h3",{attrs:{id:"낮은-품질의-데이터"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#낮은-품질의-데이터"}},[v._v("#")]),v._v(" 낮은 품질의 데이터")]),v._v(" "),a("p",[v._v("데이터에서 이상치가 확실하다면, 제거하는 것이 좋다.")]),v._v(" "),a("p",[v._v("데이터 중 일부 샘플의 특성이 누락되었다면, 해당 샘플을 제외할지, 빠진 값을 채울지, 혹은 모델을 따로 돌릴지 등은 연구자가 고민해봐야 한다.")]),v._v(" "),a("h3",{attrs:{id:"관련-없는-특성"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#관련-없는-특성"}},[v._v("#")]),v._v(" 관련 없는 특성")]),v._v(" "),a("p",[v._v("머신러닝에 사용할 좋은 특성을 찾는 작업은 중요하다. 이러한 과정을 특성 공학(feature engineering)이라고 하며, 다음과 같은 작업들이 포함된다.")]),v._v(" "),a("ul",[a("li",[v._v("특성 선택")]),v._v(" "),a("li",[v._v("특성 추출: 특성을 합쳐서 더 유용한 특성을 만듦")]),v._v(" "),a("li",[v._v("새로운 데이터 수집")])]),v._v(" "),a("h3",{attrs:{id:"훈련-데이터-과대적합"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#훈련-데이터-과대적합"}},[v._v("#")]),v._v(" 훈련 데이터 과대적합")]),v._v(" "),a("p",[v._v("오버핏팅을 해결하기 위해서는 다음과 같은 방식을 이용한다.")]),v._v(" "),a("ul",[a("li",[v._v("파라미터 수가 적은 모델을 쓰거나, 특성 수를 줄이거나, 모델에 제약을 가하여 단순화한다.")]),v._v(" "),a("li",[v._v("훈련 데이터를 더 많이 모은다.")]),v._v(" "),a("li",[v._v("훈련 데이터의 잡음을 줄인다. (오류 데이터 및 이상치 제거)")])]),v._v(" "),a("p",[v._v("규제(regularization)는 과대적합을 방지하기 위해 모델에 제약을 가하는 것을 의미한다. 모델을 조정하는 속성을 파라미터라고 하는데, 모델이 아니라 학습 알고리즘 자체의 파라미터는 하이퍼파라미터라고 한다. 규제 하이퍼파라미터를 키우면, 점점 평편한 모델로 바뀌게 된다.")]),v._v(" "),a("h3",{attrs:{id:"과소적합"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#과소적합"}},[v._v("#")]),v._v(" 과소적합")]),v._v(" "),a("p",[v._v("과소적합은 모델이 잘 안 맞는다는 뜻인데, 해결하기 위해서는 다음과 같은 방안들이 있다.")]),v._v(" "),a("ul",[a("li",[v._v("파라미터가 더 많은 강력한 모델을 고른다.")]),v._v(" "),a("li",[v._v("더 좋은 특성을 발굴한다.")]),v._v(" "),a("li",[v._v("모델의 제약을 줄인다.")])]),v._v(" "),a("h2",{attrs:{id:"테스트와-검증"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#테스트와-검증"}},[v._v("#")]),v._v(" 테스트와 검증")]),v._v(" "),a("p",[v._v("훈련 세트와 테스트 세트로 나누어 모델을 테스트한다. 새로운 샘플에 대한 오류 비율을 일반화 오차(generalization error) 혹은 외부샘플오차(out-of-sample error)라고 하며, 테스트 세트를 평가함으로써 발생하는 오차에 대한 추정값을 통해 예측할 수 있다.")]),v._v(" "),a("p",[v._v("보통 8:2로 훈련셋과 테스트 셋을 나눈다. 최적의 하이퍼파라미터를 찾기 위해서는 하나의 데이터 셋이 더 필요하다. 검증 세트(validation set)이라고 부르는 두 번째 홀드아웃 세트를 만들어서 해결한다. 훈련데이터에서 검증 세트로 너무 많은 양을 뺏기지 않기 위해 보통 교차 검증(cross-validation) 기법을 사용한다. 훈련세트를 여러세트로 만들고, 서브셋 조합으로 훈련을 시키고, 나머지로 검증하는 것이다.")]),v._v(" "),a("p",[v._v('데이비드 월퍼트는 "The Lack of A Priori Distinctions Between Learning Algorithms"라는 논문에서 데이터에 관해 완벽하게 어떤 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없음을 보였다. 공짜 점심 없음(No Free Lunch, NFL) 이론이라고도 하는데, 경험하기 전까지는 어떤 모델이 더 잘 맞을지 단정할 수 없다는 것이다.')])])}),[],!1,null,null,null);_.default=r.exports}}]);