(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{432:function(_,v,t){"use strict";t.r(v);var r=t(25),e=Object(r.a)({},(function(){var _=this,v=_.$createElement,t=_._self._c||v;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("h1",{attrs:{id:"머신러닝으로-할-수-있는-일"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝으로-할-수-있는-일"}},[_._v("#")]),_._v(" 머신러닝으로 할 수 있는 일")]),_._v(" "),t("h2",{attrs:{id:"머신러닝-알고리즘-선택-방법"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#머신러닝-알고리즘-선택-방법"}},[_._v("#")]),_._v(" 머신러닝 알고리즘 선택 방법")]),_._v(" "),t("ul",[t("li",[_._v("분류")]),_._v(" "),t("li",[_._v("회귀")]),_._v(" "),t("li",[_._v("군집화")]),_._v(" "),t("li",[_._v("차원 축소")]),_._v(" "),t("li",[_._v("그 외\n"),t("ul",[t("li",[_._v("추천")]),_._v(" "),t("li",[_._v("이상 탐지")]),_._v(" "),t("li",[_._v("고빈도 패턴 마이닝")]),_._v(" "),t("li",[_._v("강화 학습")])])])]),_._v(" "),t("p",[_._v("사이킷런 튜토리얼에서는 "),t("a",{attrs:{href:"http://scikit-learn.org/stable/tutorial/machine_learning_map/",target:"_blank",rel:"noopener noreferrer"}},[_._v("모델 선택을 위한 플로우 차트"),t("OutboundLink")],1),_._v("를 제공하고 있다.")]),_._v(" "),t("p",[_._v("학습에 사용되는 데이터 수, 연속/비연속, 정답 레이블 존재유무 등이 핵심요소이다. 특히 데이터 수가 너무 많을 때는 온라인 학습 알고리즘을 이용할 수 있다.")]),_._v(" "),t("h3",{attrs:{id:"사이킷런이-제공하는-온라인-학습-알고리즘"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#사이킷런이-제공하는-온라인-학습-알고리즘"}},[_._v("#")]),_._v(" 사이킷런이 제공하는 온라인 학습 알고리즘")]),_._v(" "),t("p",[_._v("사이킷런은 분류용으로 "),t("code",[_._v("SGDClassifier")]),_._v("와 회귀용 "),t("code",[_._v("SGDRegressor")]),_._v("를 제공한다. 손실함수와 규제항에 따라 SVM, 로지스틱 회귀, SVR과 비슷한 성능을 보여준다. 온라인 학습이 가능한 선형 분리기로는 Passive Agressive 알고리즘을 제공하지만, SCW나 AROW와 같은 비교적 최신 알고리즘은 제공하지 않는다. "),t("code",[_._v("0.18.0")]),_._v("부터 신경망용 ADAM 구현이 추가되었으며, "),t("code",[_._v("MLPClassifier")]),_._v(" 클래스에서 이용할 수 있다.")]),_._v(" "),t("h2",{attrs:{id:"분류"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#분류"}},[_._v("#")]),_._v(" 분류")]),_._v(" "),t("p",[_._v("살펴볼 분류 알고리즘은 다음과 같다.")]),_._v(" "),t("ul",[t("li",[_._v("퍼셉트론")]),_._v(" "),t("li",[_._v("로지스틱 회귀")]),_._v(" "),t("li",[_._v("서포트 벡터 머신")]),_._v(" "),t("li",[_._v("신경망")]),_._v(" "),t("li",[_._v("k-최근접 이웃(k-NN)")]),_._v(" "),t("li",[_._v("결정 트리")]),_._v(" "),t("li",[_._v("랜덤 포레스트")]),_._v(" "),t("li",[_._v("경사 부스팅 결정 트리(GBDT)")])]),_._v(" "),t("p",[_._v("퍼셉트론, 로지스틱 회귀, SVM, 신경망은 두 클래스의 경계면에 대한 함수를 학습한다. 경계면 함수란 두 클래스를 구분하는 초평면을 이야기하며, 결정 경계(Decision Boundary)라고도 한다. k-NN은 거리를 기준으로 판단하며, 나머지 셋은 트리 구조로 규칙집합을 학습한다.")]),_._v(" "),t("p",[_._v("이외에도 텍스트 분류에 많이 사용되는 나이브 베이즈나 음성인식에 오랫동안 사용된 은닉 마르코프 모델(HMM) 등도 있다. 이들 알고리즘은 데이터에 잠재된 확률분포를 추정하는 방법으로 모델링한다.")]),_._v(" "),t("h3",{attrs:{id:"퍼셉트론"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#퍼셉트론"}},[_._v("#")]),_._v(" 퍼셉트론")]),_._v(" "),t("p",[_._v("(단순) 퍼셉트론은 입력벡터에 가중치 벡터를 곱한 합을 기준으로 이진 분류하는 알고리즘이다. 퍼셉트론은 온라인 학습 방식을 취하고, 성능은 보통이지만, 학습이 빠르다. 과적합되기 쉬우며, 선형 분리 가능한 문제만 풀 수 있다.")]),_._v(" "),t("p",[_._v("온라인 학습은 데이터를 하나씩 넣으면서 학습하는 방식이고, 배치학습은 데이터를 한꺼번에 입력해서 최적화하는 방식이다. 과적합은 특성수를 줄이거나, 규제항을 도입하거나, 더 간단한 알고리즘을 적용함으로써 방지할 수 있는데, 전통적인 퍼셉트론에서는 과적합을 억제하는 구조가 없다.")]),_._v(" "),t("p",[_._v("과적합과 반대되는 현상은 과소적합(underfitting)이라고 하는데, 도메인의 고유한 특징을 포함하지 못했거나, 표현력이 낮거나, 규제항이 지나치게 강한 경우에 발생한다.")]),_._v(" "),t("p",[_._v("또한 선형 분리 가능(linearly separable)한 문제만 풀수 있는데, 대표적으로 배타적 논리합(exclusive or, XOR) 문제를 풀지 못한다. 이를 제대로 풀지 못하는 예제는 깃헙 저장소의 "),t("a",{attrs:{href:"https://github.com/flourscent/ml-at-work/blob/master/chap02/Decision_boundary.ipynb",target:"_blank",rel:"noopener noreferrer"}},[_._v("chap02/Decision_boundary.ipynb"),t("OutboundLink")],1),_._v("에서 확인할 수 있다.")])])}),[],!1,null,null,null);v.default=e.exports}}]);